{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b411df8ca2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import sys\n",
    "import string\n",
    "from csv import reader\n",
    "from functools import reduce\n",
    "from pyspark.sql import functions as f\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tableCollections import TableCollections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "                .builder \\\n",
    "                .appName(\"TableCollections\") \\\n",
    "                .config(\"spark.io.compression.codec\", \"snappy\") \\\n",
    "                .config(\"spark.shuffle.service.enabled\", \"false\") \\\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "                .config(\"spark.rdd.compress\", \"true\") \\\n",
    "                .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: ReturnIntersecWithinCols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/qgea-i56i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkingTable = spark.read.format('csv').options(header='true',inferschema='true').load('/user/ecc290/HW1data/parking-violations-header.csv')\n",
    "openTable = spark.read.format('csv').options(header='true',inferschema='true').load('/user/ecc290/HW1data/open-violations-header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num metadata file exists for table open\n",
      "string metadata file exists for table open\n",
      "num metadata file exists for table parking\n",
      "timestamp metadata file exists for table parking\n",
      "string metadata file exists for table parking\n",
      "+---------+-----+\n",
      "|col_value|count|\n",
      "+---------+-----+\n",
      "|  GWR6544|    2|\n",
      "|  GMZ6430|    2|\n",
      "|  GTZ3429|    2|\n",
      "|  GWH8612|    2|\n",
      "|  GKJ3196|    2|\n",
      "|  HCT2162|    2|\n",
      "|  JKX3874|    2|\n",
      "|  JDA2966|    2|\n",
      "| MAGUJ0DE|    2|\n",
      "|  HAX7497|    2|\n",
      "| T682962C|    2|\n",
      "|  GFC7118|    2|\n",
      "|  GUX8085|    2|\n",
      "|  GYD6262|    2|\n",
      "|  GMB9512|    2|\n",
      "|  GZC3304|    2|\n",
      "|  HFA1602|    2|\n",
      "|  HBU4498|    2|\n",
      "|  HCN8863|    2|\n",
      "|  GXN8364|    2|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TableCollections(spark, sc)\n",
    "tc.register(openTable, \"open\")\n",
    "tc.register(parkingTable, \"parking\")\n",
    "columns = [\"parking^plate_id\", \"open^plate\"]\n",
    "tc.intersecWithinCols(columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: frequentVals()\n",
    "Input: list of columns (possibly from multiple tables), integer topN  \n",
    "Output: topN rows from union of the columns with topN frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num metadata file exists for table TableOne\n",
      "string metadata file exists for table TableOne\n",
      "+--------------------+-------+-------------+\n",
      "|           col_value|    cnt|     col_name|\n",
      "+--------------------+-------+-------------+\n",
      "|              STREET|1841239|PREM_TYP_DESC|\n",
      "|RESIDENCE - APT. ...|1158315|PREM_TYP_DESC|\n",
      "|     RESIDENCE-HOUSE| 549568|PREM_TYP_DESC|\n",
      "|RESIDENCE - PUBLI...| 419936|PREM_TYP_DESC|\n",
      "|               OTHER| 148410|PREM_TYP_DESC|\n",
      "| COMMERCIAL BUILDING| 144019|PREM_TYP_DESC|\n",
      "|TRANSIT - NYC SUBWAY| 117859|PREM_TYP_DESC|\n",
      "|    DEPARTMENT STORE| 107343|PREM_TYP_DESC|\n",
      "|         CHAIN STORE| 107217|PREM_TYP_DESC|\n",
      "|       PUBLIC SCHOOL|  71369|PREM_TYP_DESC|\n",
      "+--------------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TableCollections(spark, sc)\n",
    "tc.register(t1, \"TableOne\")\n",
    "# tc.register(parkingTable, \"parking\")\n",
    "columns = [\"TableOne^PREM_TYP_DESC\"]\n",
    "tc.frequentVals(columns, 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: getCardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/kpav-sd4t.csv')\n",
    "t3 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/ay9k-vznm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num metadata file exists for table TableTwo\n",
      "string metadata file exists for table TableTwo\n",
      "num metadata file exists for table TableThree\n",
      "string metadata file exists for table TableThree\n",
      "+-------------+-----+\n",
      "|     col_name|count|\n",
      "+-------------+-----+\n",
      "|SubSectorName|   28|\n",
      "|       Agency|   45|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TableCollections(spark, sc)\n",
    "tc.register(t2, \"TableTwo\")\n",
    "tc.register(t3, \"TableThree\")\n",
    "columns = [\"TableTwo^Agency\", \"TableThree^SubSectorName\"]\n",
    "tc.getCardinality(columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: colsWithAndWithout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EX1: Is Brooklyn misclassified as a city?\n",
    "An empty result means that no columns misclassified Brooklyn as a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/swpk-hqdp.csv')\n",
    "t5 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/xi7c-iiu2.csv')\n",
    "t6 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/qcdj-rwhu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num metadata file exists for table TableFour\n",
      "string metadata file exists for table TableFour\n",
      "num metadata file exists for table TableFive\n",
      "string metadata file exists for table TableFive\n",
      "num metadata file exists for table TableSix\n",
      "string metadata file exists for table TableSix\n",
      "There are no columns that satisfies the condition\n"
     ]
    }
   ],
   "source": [
    "tc = TableCollections(spark, sc)\n",
    "tc.register(t4, \"TableFour\")\n",
    "tc.register(t5, \"TableFive\")\n",
    "tc.register(t6, \"TableSix\")\n",
    "columns = [\"TableFour^Borough\", \"TableFive^Borough\", \"TableSix^CITY\"]\n",
    "\n",
    "tc.colsWithAndWithout(columns, [\"BROOKLYN\", \"NEW YORK\"], [\"MANHATTAN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EX2: Is this column cuisine type or nationality?\n",
    "\n",
    "An empty result means that the column is for cuisine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = spark.read.format('csv').options(header='true',inferschema='true').load('/user/jh5990/open_data_csv/43nn-pn8j.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no columns that satisfies the condition\n"
     ]
    }
   ],
   "source": [
    "tc = TableCollections(spark, sc)\n",
    "tc.register(t7, \"TableSeven\")\n",
    "\n",
    "columns = [\"TableSeven^CUISINE DESCRIPTION\"]\n",
    "\n",
    "tc.colsWithAndWithout(columns, [\"American\", \"Italian\"], [\"Bakery\", \"Donuts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
